{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_mining_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOD7QaXtXNT8CS+gLjWk4V+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CgriefTesla/Dairy-of-algorithm/blob/main/Text_mining_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7dc-nim1kw7"
      },
      "source": [
        "Importing some necessary lib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "363ti_QlO1C4"
      },
      "source": [
        "## importing lib\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import collections"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kldVYTC32Tb4"
      },
      "source": [
        "Downloading some model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s12u8ipPIGF",
        "outputId": "dddfff59-6f79-4f15-f2db-946bc6ab2c61"
      },
      "source": [
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"brown\")\n",
        "nltk.download(\"punkt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln7enlVa2s_U"
      },
      "source": [
        "## Checking the data in Brown.\n",
        "\n",
        "The Corpus consists of 500 samples, distributed across 15 genres in rough proportion to the amount published in 1961 in each of those genres. All works sampled were published in 1961; as far as could be determined they were first published then, and were written by native speakers of American English.\n",
        "\n",
        "Each sample began at a random sentence-boundary in the article or other unit chosen, and continued up to the first sentence boundary after 2,000 words. In a very few cases miscounts led to samples being just under 2,000 words.\n",
        "\n",
        "The original data entry was done on upper-case only keypunch machines; capitals were indicated by a preceding asterisk, and various special items such as formulae also had special codes.\n",
        "\n",
        "The corpus originally (1961) contained 1,014,312 words sampled from 15 text categories:\n",
        "\n",
        "  \n",
        "\n",
        "*   A. PRESS: Reportage (44 texts)\n",
        "\n",
        "    1 Political\n",
        "\n",
        "    2 Sports\n",
        "\n",
        "    3 Society\n",
        "\n",
        "    4 Spot News\n",
        "\n",
        "    5 Financial\n",
        "\n",
        "    6 Cultural\n",
        "\n",
        "*   B. PRESS: Editorial (27 texts)\n",
        "\n",
        "    1 Institutional Daily\n",
        "\n",
        "    2 Personal\n",
        "\n",
        "    3 Letters to the Editor\n",
        "\n",
        "*   C. PRESS: Reviews (17 texts)\n",
        "\n",
        "    1 theatre\n",
        "\n",
        "    2 books\n",
        "\n",
        "    3 music\n",
        "\n",
        "    4 dance\n",
        "*   D. RELIGION (17 texts)\n",
        "\n",
        "    1 Books\n",
        "\n",
        "    2 Periodicals\n",
        "\n",
        "    3 Tracts\n",
        "*   E. SKILL AND HOBBIES (36 texts)\n",
        "\n",
        "    1 Books\n",
        "\n",
        "    2 Periodicals\n",
        "*   F. POPULAR LORE (48 texts)\n",
        "\n",
        "    1 Books\n",
        "\n",
        "    2 Periodicals\n",
        "*   G. BELLES-LETTRES - Biography, Memoirs, etc. (75 texts)\n",
        "\n",
        "    1 Books\n",
        "\n",
        "    2 Periodicals\n",
        "*   H. MISCELLANEOUS: US Government & House Organs (30 texts)\n",
        "\n",
        "    1 Government Documents\n",
        "\n",
        "    2 Foundation Reports\n",
        "\n",
        "    3 Industry Reports\n",
        "\n",
        "    4 College Catalog\n",
        "\n",
        "    5 Industry House organ\n",
        "*   J. LEARNED (80 texts)\n",
        "\n",
        "    1 Natural Sciences\n",
        "\n",
        "    2 Medicine\n",
        "\n",
        "    3 Mathematics\n",
        "\n",
        "    4 Social and Behavioral Sciences\n",
        "\n",
        "    5 Political Science, Law, Education\n",
        "\n",
        "    6 Humanities\n",
        "\n",
        "    7 Technology and Engineering\n",
        "*   K. FICTION: General (29 texts)\n",
        "\n",
        "    1 Novels\n",
        "\n",
        "    2 Short Stories\n",
        "*   L. FICTION: Mystery and Detective Fiction (24 texts)\n",
        "\n",
        "    1 Novels\n",
        "\n",
        "    2 Short Stories\n",
        "*   M. FICTION: Science (6 texts)\n",
        "\n",
        "    1 Novels\n",
        "\n",
        "    2 Short Stories\n",
        "*   N. FICTION: Adventure and Western (29 texts)\n",
        "\n",
        "    1 Novels\n",
        "\n",
        "    2 Short Stories\n",
        "*   P. FICTION: Romance and Love Story (29 texts)\n",
        "\n",
        "    1 Novels\n",
        "\n",
        "    2 Short Stories\n",
        "*   R. HUMOR (9 texts)\n",
        "\n",
        "    1 Novels\n",
        "\n",
        "    2 Essays, etc.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzjDpWIyWx7S",
        "outputId": "abcfb328-ed74-49b0-9607-e841923e26a3"
      },
      "source": [
        "from nltk.corpus import brown as corpus\n",
        "\n",
        "for n,item in enumerate(corpus.words(corpus.fileids()[0])[:300]):\n",
        "    print(item, end=\" \")\n",
        "    if (n%25) ==24:\n",
        "      print(\" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cn23\n",
            "The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place .  \n",
            "The jury further said in term-end presentments that the City Executive Committee , which had over-all charge of the election , `` deserves the praise  \n",
            "and thanks of the City of Atlanta '' for the manner in which the election was conducted . The September-October term jury had been charged  \n",
            "by Fulton Superior Court Judge Durwood Pye to investigate reports of possible `` irregularities '' in the hard-fought primary which was won by Mayor-nominate Ivan  \n",
            "Allen Jr. . `` Only a relative handful of such reports was received '' , the jury said , `` considering the widespread interest in  \n",
            "the election , the number of voters and the size of this city '' . The jury said it did find that many of Georgia's  \n",
            "registration and election laws `` are outmoded or inadequate and often ambiguous '' . It recommended that Fulton legislators act `` to have these laws  \n",
            "studied and revised to the end of modernizing and improving them '' . The grand jury commented on a number of other topics , among  \n",
            "them the Atlanta and Fulton County purchasing departments which it said `` are well operated and follow generally accepted practices which inure to the best  \n",
            "interest of both governments '' . Merger proposed However , the jury said it believes `` these two offices should be combined to achieve greater  \n",
            "efficiency and reduce the cost of administration '' . The City Purchasing Department , the jury said , `` is lacking in experienced clerical personnel  \n",
            "as a result of city personnel policies '' . It urged that the city `` take steps to remedy '' this problem . Implementation of  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLAJE0eu6p4S"
      },
      "source": [
        "## Checking the texts in documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSllTxFDX-Np",
        "outputId": "6f665108-f975-40a4-bf30-39f5faae3bea"
      },
      "source": [
        "## The number of documents\n",
        "len(corpus.fileids())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSoKJk6fYDj0",
        "outputId": "02050329-1374-4eb0-cdd8-7f1df16b3663"
      },
      "source": [
        "docs=[corpus.words(fileid) for fileid in corpus.fileids()]\n",
        "print(corpus.words('ca01'))\n",
        "print('----------------')\n",
        "print(docs[:5])\n",
        "print(\"num of docs:\", len(docs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]\n",
            "----------------\n",
            "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...], ['Austin', ',', 'Texas', '--', 'Committee', 'approval', ...], ['Several', 'defendants', 'in', 'the', 'Summerdale', ...], ['Oslo', 'The', 'most', 'positive', 'element', 'to', ...], ['East', 'Providence', 'should', 'organize', 'its', ...]]\n",
            "num of docs: 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJLAXeDs6353"
      },
      "source": [
        "## get the stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zdSJtI7aXs0"
      },
      "source": [
        "## English stopwords\n",
        "\n",
        "# English stopwords defined by the NLTK package.\n",
        "en_stop = nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MncHnYpv6-LY"
      },
      "source": [
        "## Data preprocess\n",
        "\n",
        "\n",
        "*   coverting to lowercase\n",
        "*   remove some stopwords and  ','\n",
        "*   lemmatize\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZthSLAMIbHdq"
      },
      "source": [
        "## data preprocess\n",
        "\n",
        "from nltk.corpus import wordnet as wn # import for lemmatize\n",
        "\n",
        "def preprocess_word(word, stopwordset):\n",
        "    \n",
        "    #1.convert words to lowercase (e.g., Python =>python)\n",
        "    word=word.lower()\n",
        "    \n",
        "    #2.remove \",\" and \".\"\n",
        "    if word in [\",\",\".\"]:\n",
        "        return None\n",
        "    \n",
        "    #3.remove stopwords  (e.g., the => (None)) \n",
        "    if word in stopwordset:\n",
        "        return None\n",
        "    \n",
        "    #4.lemmatize  (e.g., cooked=>cook)\n",
        "    lemma = wn.morphy(word)\n",
        "    if lemma is None:\n",
        "        return word\n",
        "\n",
        "    # lemmatized words could be in the stopwords set\n",
        "    elif lemma in stopwordset: \n",
        "        return None\n",
        "    else:\n",
        "        return lemma\n",
        "    \n",
        "\n",
        "def preprocess_document(document):\n",
        "    document=[preprocess_word(w, en_stop) for w in document]\n",
        "    document=[w for w in document if w is not None]\n",
        "    return document\n",
        "\n",
        "def preprocess_documents(documents):\n",
        "    return [preprocess_document(document) for document in documents]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbRMNctb7UI6"
      },
      "source": [
        "## Checking the function using the first document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDfrEqdub3il",
        "outputId": "065c9d2e-c262-42f8-919b-419eb9fa4e3f"
      },
      "source": [
        "## check the function of data preprocess\n",
        "\n",
        "# before\n",
        "print(docs[0][:25]) \n",
        "\n",
        "# after\n",
        "print(preprocess_documents(docs)[0][:25])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n",
            "['fulton', 'county', 'grand', 'jury', 'say', 'friday', 'investigation', \"atlanta's\", 'recent', 'primary', 'election', 'produce', '``', 'evidence', \"''\", 'irregularity', 'take', 'place', 'jury', 'say', 'term-end', 'presentment', 'city', 'executive', 'committee']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5ZCap-e7tld"
      },
      "source": [
        "## Calculating the documents embedding(vector).\n",
        "\n",
        "Here I use tf-idf vectorizer to process the document\n",
        "\n",
        "Ignoring the one letter words\n",
        "\n",
        "Setting the max_feature to the Square root of the number of words, 1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yF_zXflcX6p",
        "outputId": "4c947b03-dede-4885-e064-b36cf9866835"
      },
      "source": [
        "## clustering\n",
        "# define the vectorizer\n",
        "pre_docs=preprocess_documents(docs)\n",
        "pre_docs=[\" \".join(doc) for doc in pre_docs]\n",
        "print(pre_docs[0])\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=1000, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b' )\n",
        "\n",
        "\n",
        "# fit\n",
        "tf_idf = vectorizer.fit_transform(pre_docs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fulton county grand jury say friday investigation atlanta's recent primary election produce `` evidence '' irregularity take place jury say term-end presentment city executive committee over-all charge election `` deserve praise thanks city atlanta '' manner election conduct september-october term jury charge fulton superior court judge durwood pye investigate report possible `` irregularity '' hard-fought primary mayor-nominate ivan allen jr. `` relative handful report receive '' jury say `` consider widespread interest election number voter size city '' jury say find many georgia's registration election laws `` outmode inadequate often ambiguous '' recommend fulton legislator act `` laws study revise end modernize improve '' grand jury comment number topic among atlanta fulton county purchasing department say `` well operate follow generally accept practice inure best interest government '' merger propose however jury say belief `` two office combine achieve greater efficiency reduce cost administration '' city purchasing department jury say `` lack experience clerical personnel result city personnel policy '' urge city `` take steps remedy '' problem implementation georgia's automobile title law also recommend outgo jury urge next legislature `` provide enable funds re-set effective date orderly implementation law may effect '' grand jury take swipe state welfare department's handling federal funds grant child welfare services foster home `` one major item fulton county general assistance program '' jury say state welfare department `` see fit distribute funds welfare department county state exception fulton county receive none money juror say realize `` proportionate distribution funds might disable program le populous county '' nevertheless `` feel future fulton county receive portion available funds '' juror say `` failure continue place disproportionate burden '' fulton taxpayer jury also comment fulton ordinary's court fire practice appointment appraiser guardian administrator awarding fee compensation ward protect jury say found court `` incorporate operate procedure recommendation '' two previous grand jury atlanta bar association interim citizen committee `` action serve protect fact effect court's ward undue costs appoint elect servant unmeritorious criticism '' jury say regard atlanta's new multi-million-dollar airport jury recommend `` new management take charge jan. 1 airport operate manner eliminate political influence '' jury elaborate add `` periodic surveillance pricing practice concessionaire purpose keeping price reasonable '' ask jail deputy matter jury recommend : ( 1 ) four additional deputy employ fulton county jail `` doctor medical intern extern employ night weekend duty jail '' ( 2 ) fulton legislator `` work city official pass enable legislation permit establishment fair equitable '' pension plan city employ jury praise administration operation atlanta police department fulton tax commissioner's office bellwood alpharetta prison farm grady hospital fulton health department mayor william b. hartsfield file suit divorce wife pearl williams hartsfield fulton superior court friday petition charge mental cruelty couple married aug. 2 1913 son william berry jr. daughter mrs. j. m. cheshire griffin attorney mayor say amicable property settlement agree upon petition list mayor's occupation `` attorney '' age 71 list wife's age 74 place birth opelika ala. petition say couple live together man wife year hartsfield home 637 e. pelham rd. aj henry l. bowden list petition mayor's attorney hartsfield mayor atlanta exception one brief interlude since 1937 political career go back election city council 1923 mayor's present term office expire jan. 1 succeed ivan allen jr. become candidate sept. 13 primary mayor hartsfield announce would run reelection georgia republican getting strong encouragement enter candidate 1962 governor's race top official say wednesday robert snodgrass state gop chairman say meeting hold tuesday night blue ridge bring enthusiastic response audience state party chairman james w. dorsey add enthusiasm picking state rally hold sept. 8 savannah newly elect texas sen. john tower feature speaker blue ridge meeting audience warn entering candidate governor would force take petition voting precinct obtain signature register voter despite warning unanimous vote enter candidate accord republican attend crowd ask whether want wait one term make race vote -- dissent large hurdle republican would face state law say making first race one two alternative course must take : 1 five per cent voter county must sign petition request republican allow place names candidate general election ballot 2 republican must hold primary county unit system -- system party oppose platform sam caldwell state highway department public relations director resign tuesday work lt. gov. garland byrd's campaign caldwell's resignation expect time succeed rob ledford gainesville assistant three years gubernatorial campaign start caldwell expect become campaign coordinator byrd georgia legislature wind 1961 session monday head home -- highway bond money approve follow shortly adjournment monday afternoon senate expect approve study number legislator allot rural urban area determine adjustment make gov. vandiver expect make traditional visit chambers work toward adjournment vandiver likely mention $100 million highway bond issue approve earlier session first priority item construction bond meanwhile learn state highway department near ready issue first $30 million worth highway reconstruction bond bond issue go state court friendly test suit test validity act sales begin contract let repair work georgia's heavily travel highway highway department source say also plan issue $3 million $4 million worth rural roads authority bond rural road construction work revolve fund department apparently intend make rural roads authority revolve fund new bond would issue every time portion old one pay tax authorities vandiver open race governor 1958 battle legislature issuance $50 million worth additional rural roads bond propose gov. marvin griffin highway department source tell constitution however vandiver consult yet plan issue new rural roads bond schley county rep. b. d. pelham offer resolution monday house rescind body's action friday voting $10 per day increase expense allowance pelham say sunday night research whether `` quickie '' vote increase repeal outright whether notice would first given reconsideration action would seek emphasizing technical details fully work pelham say resolution would seek set aside privilege resolution house vote 87-31 similar resolution pass senate vote 29-5 sunday night word resolution offer rescind action pelham point georgia voter last november reject constitutional amendment allow legislator vote pay raise future legislature sessions veteran jackson county legislator ask georgia house monday back federal aid education something consistently oppose past rep. mac barber commerce asking house privilege resolution `` endorse increase federal support public education provide funds receive expend '' state funds barber 13th year legislator say `` member congressional delegation washington would like see ( resolution ) pass '' add none georgia's congressman specifically ask offer resolution resolution barber toss house hopper friday formally read monday say `` event congress provide increase federal funds '' state board education direct `` give priority '' teacher pay raise colquitt -- long hot controversy miller county new school superintendent elect policeman put `` cool election ever saw county '' new school superintendent harry davis veteran agriculture teacher defeated felix bush school principal chairman miller county democratic executive committee davis receive 1,119 vote saturday's election bush get 402 ordinary carey williams arm pistol stand polls insure order `` cool calm election ever saw '' colquitt policeman tom williams say `` polls like church smell drop liquor bit trouble '' campaign leading election quiet however mark controversy anonymous midnight phone call veil threat violence former county school superintendent george p. callan shot death march 18 four days resign post dispute county school board election campaign candidate davis bush reportedly receive anonymous telephone call ordinary williams say subject anonymous call soon schedule election many local citizen fear would irregularity polls williams get permit carry gun promise orderly election sheriff felix tabb say ordinary apparently make good promise `` everything go real smooth '' sheriff say `` bit trouble ''\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTbEw5817srt"
      },
      "source": [
        "## K-means with Euclidean distance\n",
        "\n",
        "## convert the categories into int list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I76WQEQSB_v",
        "outputId": "266bf009-c4f1-478c-e9a9-ce352d6311f3"
      },
      "source": [
        "print('This is categories:',corpus.categories(corpus.fileids()))\n",
        "\n",
        "labels = corpus.fileids()\n",
        "print('This is raw ground truth labels:',labels)\n",
        "from string import digits\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "labels_l = []\n",
        "for label in labels:\n",
        "  label = label.translate(remove_digits)\n",
        "  labels_l.append(label)\n",
        "print('This is processed ground truth labels:', labels_l)\n",
        "\n",
        "dic = {'ca':0,'cb':1,'cc':2, 'cd':3,'ce':4, 'cf':5,'cg':6,'ch':7, 'cj':8,'ck':9,'cl':10, 'cm':11,'cn':12,'cp':13,'cr': 14}\n",
        "true_labels = []\n",
        "\n",
        "for i in labels_l:\n",
        "  true_labels.append(dic[i])\n",
        "print('This is converted ground truth:',true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is categories: ['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n",
            "This is raw ground truth labels: ['ca01', 'ca02', 'ca03', 'ca04', 'ca05', 'ca06', 'ca07', 'ca08', 'ca09', 'ca10', 'ca11', 'ca12', 'ca13', 'ca14', 'ca15', 'ca16', 'ca17', 'ca18', 'ca19', 'ca20', 'ca21', 'ca22', 'ca23', 'ca24', 'ca25', 'ca26', 'ca27', 'ca28', 'ca29', 'ca30', 'ca31', 'ca32', 'ca33', 'ca34', 'ca35', 'ca36', 'ca37', 'ca38', 'ca39', 'ca40', 'ca41', 'ca42', 'ca43', 'ca44', 'cb01', 'cb02', 'cb03', 'cb04', 'cb05', 'cb06', 'cb07', 'cb08', 'cb09', 'cb10', 'cb11', 'cb12', 'cb13', 'cb14', 'cb15', 'cb16', 'cb17', 'cb18', 'cb19', 'cb20', 'cb21', 'cb22', 'cb23', 'cb24', 'cb25', 'cb26', 'cb27', 'cc01', 'cc02', 'cc03', 'cc04', 'cc05', 'cc06', 'cc07', 'cc08', 'cc09', 'cc10', 'cc11', 'cc12', 'cc13', 'cc14', 'cc15', 'cc16', 'cc17', 'cd01', 'cd02', 'cd03', 'cd04', 'cd05', 'cd06', 'cd07', 'cd08', 'cd09', 'cd10', 'cd11', 'cd12', 'cd13', 'cd14', 'cd15', 'cd16', 'cd17', 'ce01', 'ce02', 'ce03', 'ce04', 'ce05', 'ce06', 'ce07', 'ce08', 'ce09', 'ce10', 'ce11', 'ce12', 'ce13', 'ce14', 'ce15', 'ce16', 'ce17', 'ce18', 'ce19', 'ce20', 'ce21', 'ce22', 'ce23', 'ce24', 'ce25', 'ce26', 'ce27', 'ce28', 'ce29', 'ce30', 'ce31', 'ce32', 'ce33', 'ce34', 'ce35', 'ce36', 'cf01', 'cf02', 'cf03', 'cf04', 'cf05', 'cf06', 'cf07', 'cf08', 'cf09', 'cf10', 'cf11', 'cf12', 'cf13', 'cf14', 'cf15', 'cf16', 'cf17', 'cf18', 'cf19', 'cf20', 'cf21', 'cf22', 'cf23', 'cf24', 'cf25', 'cf26', 'cf27', 'cf28', 'cf29', 'cf30', 'cf31', 'cf32', 'cf33', 'cf34', 'cf35', 'cf36', 'cf37', 'cf38', 'cf39', 'cf40', 'cf41', 'cf42', 'cf43', 'cf44', 'cf45', 'cf46', 'cf47', 'cf48', 'cg01', 'cg02', 'cg03', 'cg04', 'cg05', 'cg06', 'cg07', 'cg08', 'cg09', 'cg10', 'cg11', 'cg12', 'cg13', 'cg14', 'cg15', 'cg16', 'cg17', 'cg18', 'cg19', 'cg20', 'cg21', 'cg22', 'cg23', 'cg24', 'cg25', 'cg26', 'cg27', 'cg28', 'cg29', 'cg30', 'cg31', 'cg32', 'cg33', 'cg34', 'cg35', 'cg36', 'cg37', 'cg38', 'cg39', 'cg40', 'cg41', 'cg42', 'cg43', 'cg44', 'cg45', 'cg46', 'cg47', 'cg48', 'cg49', 'cg50', 'cg51', 'cg52', 'cg53', 'cg54', 'cg55', 'cg56', 'cg57', 'cg58', 'cg59', 'cg60', 'cg61', 'cg62', 'cg63', 'cg64', 'cg65', 'cg66', 'cg67', 'cg68', 'cg69', 'cg70', 'cg71', 'cg72', 'cg73', 'cg74', 'cg75', 'ch01', 'ch02', 'ch03', 'ch04', 'ch05', 'ch06', 'ch07', 'ch08', 'ch09', 'ch10', 'ch11', 'ch12', 'ch13', 'ch14', 'ch15', 'ch16', 'ch17', 'ch18', 'ch19', 'ch20', 'ch21', 'ch22', 'ch23', 'ch24', 'ch25', 'ch26', 'ch27', 'ch28', 'ch29', 'ch30', 'cj01', 'cj02', 'cj03', 'cj04', 'cj05', 'cj06', 'cj07', 'cj08', 'cj09', 'cj10', 'cj11', 'cj12', 'cj13', 'cj14', 'cj15', 'cj16', 'cj17', 'cj18', 'cj19', 'cj20', 'cj21', 'cj22', 'cj23', 'cj24', 'cj25', 'cj26', 'cj27', 'cj28', 'cj29', 'cj30', 'cj31', 'cj32', 'cj33', 'cj34', 'cj35', 'cj36', 'cj37', 'cj38', 'cj39', 'cj40', 'cj41', 'cj42', 'cj43', 'cj44', 'cj45', 'cj46', 'cj47', 'cj48', 'cj49', 'cj50', 'cj51', 'cj52', 'cj53', 'cj54', 'cj55', 'cj56', 'cj57', 'cj58', 'cj59', 'cj60', 'cj61', 'cj62', 'cj63', 'cj64', 'cj65', 'cj66', 'cj67', 'cj68', 'cj69', 'cj70', 'cj71', 'cj72', 'cj73', 'cj74', 'cj75', 'cj76', 'cj77', 'cj78', 'cj79', 'cj80', 'ck01', 'ck02', 'ck03', 'ck04', 'ck05', 'ck06', 'ck07', 'ck08', 'ck09', 'ck10', 'ck11', 'ck12', 'ck13', 'ck14', 'ck15', 'ck16', 'ck17', 'ck18', 'ck19', 'ck20', 'ck21', 'ck22', 'ck23', 'ck24', 'ck25', 'ck26', 'ck27', 'ck28', 'ck29', 'cl01', 'cl02', 'cl03', 'cl04', 'cl05', 'cl06', 'cl07', 'cl08', 'cl09', 'cl10', 'cl11', 'cl12', 'cl13', 'cl14', 'cl15', 'cl16', 'cl17', 'cl18', 'cl19', 'cl20', 'cl21', 'cl22', 'cl23', 'cl24', 'cm01', 'cm02', 'cm03', 'cm04', 'cm05', 'cm06', 'cn01', 'cn02', 'cn03', 'cn04', 'cn05', 'cn06', 'cn07', 'cn08', 'cn09', 'cn10', 'cn11', 'cn12', 'cn13', 'cn14', 'cn15', 'cn16', 'cn17', 'cn18', 'cn19', 'cn20', 'cn21', 'cn22', 'cn23', 'cn24', 'cn25', 'cn26', 'cn27', 'cn28', 'cn29', 'cp01', 'cp02', 'cp03', 'cp04', 'cp05', 'cp06', 'cp07', 'cp08', 'cp09', 'cp10', 'cp11', 'cp12', 'cp13', 'cp14', 'cp15', 'cp16', 'cp17', 'cp18', 'cp19', 'cp20', 'cp21', 'cp22', 'cp23', 'cp24', 'cp25', 'cp26', 'cp27', 'cp28', 'cp29', 'cr01', 'cr02', 'cr03', 'cr04', 'cr05', 'cr06', 'cr07', 'cr08', 'cr09']\n",
            "This is processed ground truth labels: ['ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'ca', 'cb', 'cb', 'cb', 'cb', 'cb', 'cb', 'cb', 'cb', 'cb', 'cb', 'cb', 'cb', 'cb', 'cb', 'cb', 'cb', 'cb', 'cb', 'cb', 'cb', 'cb', 'cb', 'cb', 'cb', 'cb', 'cb', 'cb', 'cc', 'cc', 'cc', 'cc', 'cc', 'cc', 'cc', 'cc', 'cc', 'cc', 'cc', 'cc', 'cc', 'cc', 'cc', 'cc', 'cc', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'ce', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'cg', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'ch', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'cj', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'ck', 'cl', 'cl', 'cl', 'cl', 'cl', 'cl', 'cl', 'cl', 'cl', 'cl', 'cl', 'cl', 'cl', 'cl', 'cl', 'cl', 'cl', 'cl', 'cl', 'cl', 'cl', 'cl', 'cl', 'cl', 'cm', 'cm', 'cm', 'cm', 'cm', 'cm', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cn', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cp', 'cr', 'cr', 'cr', 'cr', 'cr', 'cr', 'cr', 'cr', 'cr']\n",
            "This is converted ground truth: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bko1V1kNiqv4"
      },
      "source": [
        "## Building the function to calculate the purity score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxgIJptmb8_t"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "\n",
        "def purity_score(y_true, y_pred):\n",
        "    # compute contingency matrix (also called confusion matrix)\n",
        "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
        "    print('This is confusion matrix')\n",
        "    print('-------------------')\n",
        "    print(contingency_matrix)\n",
        "    print('-------------------')\n",
        "    # return purity\n",
        "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvRwJ8UAix9Q"
      },
      "source": [
        "# K-means setting\n",
        "\n",
        "num_clusters = 15\n",
        "km = KMeans(n_clusters=num_clusters, random_state = 0)\n",
        "\n",
        "# fit\n",
        "clusters = km.fit_predict(tf_idf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3HRBdUUjwLe"
      },
      "source": [
        "## getting the predicted_labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMKxZsbIjffi"
      },
      "source": [
        "pre_labels = []\n",
        "for doc, cls in zip(preprocess_documents(docs), clusters):\n",
        "    print(cls)\n",
        "    pre_labels.append(cls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGyc6HjacS1Y",
        "outputId": "1cc41d1a-258a-44ab-c018-ff0ea290f63a"
      },
      "source": [
        "print('This is predicted labels:',pre_labels)\n",
        "print('This is ground truth labels:', true_labels)\n",
        "\n",
        "print('This is purity score:',purity_score(true_labels, pre_labels))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is predicted labels: [4, 4, 11, 4, 2, 4, 4, 4, 4, 4, 13, 13, 13, 13, 13, 9, 9, 9, 2, 4, 9, 9, 9, 2, 4, 11, 4, 11, 9, 9, 6, 13, 9, 4, 0, 4, 4, 13, 13, 13, 4, 4, 11, 11, 4, 4, 4, 4, 4, 4, 4, 10, 2, 1, 4, 4, 1, 4, 11, 4, 4, 4, 4, 4, 4, 6, 4, 13, 4, 0, 1, 2, 13, 2, 1, 1, 1, 2, 13, 2, 7, 2, 2, 2, 2, 13, 4, 1, 7, 6, 6, 6, 6, 6, 1, 7, 6, 5, 7, 5, 13, 6, 7, 6, 6, 2, 13, 4, 1, 9, 11, 8, 8, 13, 8, 12, 13, 13, 8, 8, 8, 8, 13, 13, 11, 11, 1, 7, 12, 11, 5, 8, 11, 0, 11, 11, 11, 11, 11, 11, 11, 1, 12, 7, 2, 12, 10, 1, 1, 10, 9, 1, 1, 11, 5, 6, 12, 13, 1, 5, 4, 13, 12, 4, 2, 0, 13, 13, 2, 4, 0, 9, 1, 0, 11, 12, 12, 6, 13, 1, 4, 13, 2, 13, 6, 4, 4, 2, 6, 2, 5, 4, 12, 13, 1, 4, 2, 7, 4, 1, 7, 7, 12, 7, 7, 2, 7, 7, 11, 5, 5, 1, 4, 7, 1, 7, 2, 5, 1, 1, 9, 1, 1, 5, 4, 12, 4, 1, 2, 9, 5, 7, 7, 4, 5, 10, 12, 1, 12, 10, 4, 10, 10, 6, 7, 0, 4, 1, 10, 5, 4, 7, 2, 5, 10, 10, 0, 7, 1, 7, 5, 7, 1, 10, 11, 11, 4, 11, 11, 11, 11, 4, 11, 11, 14, 4, 4, 11, 8, 11, 4, 4, 11, 11, 11, 11, 11, 11, 4, 2, 11, 0, 11, 0, 11, 14, 14, 14, 11, 14, 14, 11, 14, 13, 8, 5, 13, 14, 11, 14, 11, 14, 14, 14, 14, 5, 5, 11, 11, 11, 1, 1, 0, 1, 1, 14, 1, 11, 14, 4, 4, 11, 1, 11, 11, 5, 4, 11, 11, 4, 0, 0, 0, 11, 5, 1, 1, 7, 12, 11, 6, 4, 7, 13, 13, 1, 5, 1, 7, 7, 7, 1, 11, 11, 11, 14, 11, 11, 14, 11, 8, 14, 14, 14, 10, 12, 3, 6, 10, 6, 3, 10, 12, 6, 10, 10, 3, 10, 10, 12, 10, 10, 10, 10, 12, 9, 10, 3, 10, 3, 10, 3, 10, 3, 3, 3, 12, 3, 12, 3, 3, 3, 10, 10, 3, 3, 10, 9, 3, 3, 3, 7, 3, 12, 10, 10, 3, 10, 10, 10, 3, 1, 10, 3, 12, 12, 12, 3, 10, 12, 12, 3, 3, 12, 3, 12, 3, 12, 3, 3, 10, 10, 12, 10, 3, 12, 3, 12, 3, 3, 10, 3, 10, 10, 3, 10, 10, 3, 10, 10, 3, 10, 9, 10, 12, 3, 3, 3, 10, 3, 3, 10, 10, 10, 10, 3, 10, 12, 3, 10, 3, 10, 10, 10, 2, 10, 10, 10, 1, 10]\n",
            "This is ground truth labels: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "This is confusion matrix\n",
            "-------------------\n",
            "[[ 1  0  3  0 16  0  1  0  0  9  0  5  0  9  0]\n",
            " [ 1  3  1  0 18  0  1  0  0  0  1  1  0  1  0]\n",
            " [ 0  4  8  0  1  0  0  1  0  0  0  0  0  3  0]\n",
            " [ 0  1  0  0  0  2  9  4  0  0  0  0  0  1  0]\n",
            " [ 1  2  1  0  1  1  0  1  8  1  0 12  2  6  0]\n",
            " [ 3  8  5  0  6  2  4  1  0  2  2  2  6  7  0]\n",
            " [ 2 13  6  0 10 10  1 16  0  2  8  1  5  1  0]\n",
            " [ 2  0  1  0  7  0  0  0  1  0  0 18  0  0  1]\n",
            " [ 4 11  0  0  5  6  1  5  2  0  0 22  1  4 19]\n",
            " [ 0  0  0  6  0  0  3  0  0  1 15  0  4  0  0]\n",
            " [ 0  0  0 14  0  0  0  1  0  1  5  0  3  0  0]\n",
            " [ 0  1  0  1  0  0  0  0  0  0  4  0  0  0  0]\n",
            " [ 0  0  0 13  0  0  0  0  0  0  5  0 11  0  0]\n",
            " [ 0  0  0 11  0  0  0  0  0  1 15  0  2  0  0]\n",
            " [ 0  1  1  0  0  0  0  0  0  0  7  0  0  0  0]]\n",
            "-------------------\n",
            "This is purity score: 0.37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbA1Rm4lkOb_"
      },
      "source": [
        "# Content.\n",
        "\n",
        " I used brown dataset to do the K-means text mining. The details of the dataset is above.\n",
        "\n",
        "# similarity criteria.\n",
        "\n",
        "I converted the documents into tf-idf vectors, and calculated their Euclidean distance.\n",
        "\n",
        "# Regarding to the different K.\n",
        "\n",
        "Exactly I didn't use different K to compare the result, because this dataset has their own ground truth. So I don't think it is suitable to change the number of classes, and also if the classes was changed I don't know how to evaluate the result.\n",
        "\n",
        "# contents of clusters.\n",
        "\n",
        "I think it is better to see the confusion matrix above. In that matrix you can get the information about my result.\n",
        "\n",
        "# Evaluating\n",
        "\n",
        "The purity score of this model is 0.37 and inverse purity score is 0.39 (you could get that by changing the parameter of purity_score function. changing 'axis=0' to 'axis=1')\n",
        "\n",
        "# Consideration\n",
        "\n",
        "I don't think it is a good result, but I don't how to improve it. I think the point is that the dataset **Brown** is classified by their type of literature but not the content. So the struct of the document is more important than the content. "
      ]
    }
  ]
}